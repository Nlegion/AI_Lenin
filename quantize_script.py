import argparse
import os
import llama_cpp


def quantize_model(input_path: str, output_path: str, quant_type: str):
    """
    –ö–≤–∞–Ω—Ç—É–µ—Ç GGUF-–º–æ–¥–µ–ª—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–≥–æ API llama.cpp
    """
    print(f"üöÄ –ù–∞—á–∞–ª–æ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è: {input_path} -> {output_path} (—Ç–∏–ø: {quant_type})")

    # –ß–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –∏–∑ llama.h
    QUANT_TYPES = {
        "q4_0": 2,  # LLAMA_FTYPE_MOSTLY_Q4_0
        "q4_1": 3,  # LLAMA_FTYPE_MOSTLY_Q4_1
        "q5_0": 6,  # LLAMA_FTYPE_MOSTLY_Q5_0
        "q5_1": 7,  # LLAMA_FTYPE_MOSTLY_Q5_1
        "q8_0": 8,  # LLAMA_FTYPE_MOSTLY_Q8_0
        "q2_k": 10,  # LLAMA_FTYPE_MOSTLY_Q2_K
        "q3_k": 11,  # LLAMA_FTYPE_MOSTLY_Q3_K
        "q4_k": 12,  # LLAMA_FTYPE_MOSTLY_Q4_K
        "q5_k": 13,  # LLAMA_FTYPE_MOSTLY_Q5_K
        "q6_k": 14,  # LLAMA_FTYPE_MOSTLY_Q6_K
        "q8_k": 15,  # LLAMA_FTYPE_MOSTLY_Q8_K
        "iq1_m": 16,  # LLAMA_FTYPE_MOSTLY_IQ1_M
        "iq2_xxs": 17,  # LLAMA_FTYPE_MOSTLY_IQ2_XXS
        "iq2_xs": 18,  # LLAMA_FTYPE_MOSTLY_IQ2_XS
        "iq3_xxs": 19,  # LLAMA_FTYPE_MOSTLY_IQ3_XXS
        "iq1_s": 20,  # LLAMA_FTYPE_MOSTLY_IQ1_S
        "iq4_nl": 21,  # LLAMA_FTYPE_MOSTLY_IQ4_NL
        "iq3_s": 22,  # LLAMA_FTYPE_MOSTLY_IQ3_S
        "iq2_s": 23,  # LLAMA_FTYPE_MOSTLY_IQ2_S
        "iq4_xs": 24  # LLAMA_FTYPE_MOSTLY_IQ4_XS
    }

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤
    if quant_type not in QUANT_TYPES:
        supported = ", ".join(QUANT_TYPES.keys())
        raise ValueError(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è: {quant_type}. "
                         f"–î–æ—Å—Ç—É–ø–Ω—ã–µ: {supported}")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
    params = llama_cpp.llama_model_quantize_params(
        nthread=os.cpu_count() or 1,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤
        ftype=QUANT_TYPES[quant_type],  # –ß–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
        allow_requantize=True,  # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–µ—Ä–µ–∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
        quantize_output_tensor=False,  # –ù–µ –∫–≤–∞–Ω—Ç–æ–≤–∞—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä
        only_copy=False,  # –í—ã–ø–æ–ª–Ω—è—Ç—å –∏–º–µ–Ω–Ω–æ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ
    )

    # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
    result = llama_cpp.llama_model_quantize(
        input_path.encode('utf-8'),  # –ü—É—Ç—å –≤ –±–∞–π—Ç–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
        output_path.encode('utf-8'),
        params
    )

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if result != 0:
        raise RuntimeError(f"üî• –û—à–∏–±–∫–∞ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è! –ö–æ–¥ –æ—à–∏–±–∫–∏: {result}")

    print("‚úÖ –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='–ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ GGUF –º–æ–¥–µ–ª–µ–π')
    parser.add_argument('input', help='–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É GGUF —Ñ–∞–π–ª—É')
    parser.add_argument('output', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏')
    parser.add_argument('quant_type', help='–¢–∏–ø –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è (q4_k, q5_k_m –∏ —Ç.–¥.)')

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º
    if not os.path.exists(args.input):
        raise FileNotFoundError(f"–§–∞–π–ª {args.input} –Ω–µ –Ω–∞–π–¥–µ–Ω!")

    if not args.input.endswith(".gguf"):
        print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .gguf")

    quantize_model(args.input, args.output, args.quant_type)