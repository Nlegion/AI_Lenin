# === src/core/processor.py ===
import asyncio
import time
import logging
from src.core.database.repositories.news_repository import NewsRepository
from src.modules.news_system.fetcher import NewsFetcher
from src.core.lenin_analyzer import LeninAnalyzer
from src.core.publisher import TelegramPublisher
from src.core.settings.config import Settings
from src.core.utils.decorators import handle_errors
from src.core.database.db_core import session_scope
import gc
import torch

logger = logging.getLogger(__name__)


class NewsProcessor:
    def __init__(self):
        self.config = Settings()
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NewsFetcher")
        self.fetcher = NewsFetcher()
        self.analyzer = None
        self.analyzer_ready = asyncio.Event()
        asyncio.create_task(self.initialize_analyzer_async())
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TelegramPublisher")
        self.publisher = TelegramPublisher()
        self.stats = {"news_fetched": 0, "news_processed": 0, "analyses_published": 0, "errors": 0}

    @handle_errors
    async def initialize_analyzer_async(self):
        try:
            self.analyzer = LeninAnalyzer()
            torch.cuda.empty_cache()
            gc.collect()
        except Exception as e:
            logger.exception(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}")
            await self.publisher.send_admin_notification(f"üö® –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)[:300]}")
        finally:
            self.analyzer_ready.set()

    @handle_errors
    async def fetch_new_news(self):
        try:
            news_items = self.fetcher.fetch_all()
            async with session_scope() as session:
                repo = NewsRepository(session)
                await repo.save_news(news_items)
            self.stats["news_fetched"] += len(news_items)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –Ω–æ–≤–æ—Å—Ç–µ–π: {str(e)}")
            self.stats["errors"] += 1
            await self.publisher.send_admin_notification(f"üö® –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {str(e)}")

    @handle_errors
    async def process_pending_news(self):
        if not self.analyzer_ready.is_set():
            logger.info("–û–∂–∏–¥–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞...")
            await self.analyzer_ready.wait()

        try:
            async with session_scope() as session:
                repo = NewsRepository(session)
                unprocessed = await repo.get_unprocessed_news(limit=1)  # –ü–æ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏

                for news in unprocessed:
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–π VRAM
                    if torch.cuda.is_available() and torch.cuda.memory_allocated() > 6.5e9:
                        logger.warning("–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ VRAM, –ø—Ä–æ–ø—É—Å–∫ –Ω–æ–≤–æ—Å—Ç–∏")
                        continue
                    try:
                        gc.collect()
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()

                        loop = asyncio.get_running_loop()
                        analysis = await loop.run_in_executor(
                            None,
                            self.analyzer.generate_analysis,
                            news.title,  # –ü–µ—Ä–µ–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                            news.content  # –ü–µ—Ä–µ–¥–∞–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
                        )
                        await repo.save_analysis(news.id, analysis)
                        self.stats["news_processed"] += 1
                        # –ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—Å–∏–ª–∏ –ª–∏ –ª–∏–º–∏—Ç VRAM
                        if torch.cuda.is_available() and torch.cuda.memory_allocated() > 7e9:
                            logger.warning("–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ VRAM –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –≤—ã–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏")
                            await loop.run_in_executor(None, self.analyzer.unload_model)
                            await asyncio.sleep(3)  # –ü–∞—É–∑–∞ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
                            await loop.run_in_executor(None, self.analyzer.reload_model)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏ {news.id}: {str(e)}")
                        self.stats["errors"] += 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
            self.stats["errors"] += 1
            await self.publisher.send_admin_notification(f"üö® –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

    @handle_errors
    async def publish_pending_analyses(self):
        try:
            async with session_scope() as session:
                repo = NewsRepository(session)
                unpublished = await repo.get_unpublished_analysis(limit=10)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –ª–∏–º–∏—Ç

                for item in unpublished:
                    for attempt in range(3):  # 3 –ø–æ–ø—ã—Ç–∫–∏
                        try:
                            success = await self.publisher.publish_analysis(
                                item.news_id,
                                item.news.title,
                                item.news.url,
                                item.analysis
                            )
                            if success:
                                await repo.mark_as_published(item.news_id)
                                break  # –í—ã—Ö–æ–¥ –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
                            else:
                                await asyncio.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {str(e)}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {str(e)}")
            self.stats["errors"] += 1
            await self.publisher.send_admin_notification(f"üö® –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {str(e)}")

    @handle_errors
    async def run_full_cycle(self):
        logger.info("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        await self.fetch_new_news()
        await self.process_pending_news()
        await self.publish_pending_analyses()

        logger.info(
            f"–¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω: –ù–æ–≤–æ—Å—Ç–µ–π: {self.stats['news_fetched']}, "
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['news_processed']}, "
            f"–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {self.stats['analyses_published']}, "
            f"–û—à–∏–±–æ–∫: {self.stats['errors']}"
        )

        # –û—Ç—á–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        if self.stats['errors'] > 0:
            await self.publisher.send_admin_notification(
                f"‚ö†Ô∏è –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω —Å {self.stats['errors']} –æ—à–∏–±–∫–∞–º–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏."
            )

        # –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for key in self.stats:
            self.stats[key] = 0

    @handle_errors
    async def start_periodic_processing(self):
        logger.info("–ó–∞–ø—É—Å–∫ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        await self.publisher.send_admin_notification("üöÄ –°–∏—Å—Ç–µ–º–∞ –ò–ò-–õ–µ–Ω–∏–Ω –∑–∞–ø—É—â–µ–Ω–∞")

        # –ü–µ—Ä–≤—ã–π —Ü–∏–∫–ª
        await self.run_full_cycle()

        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        while True:
            start_time = time.time()
            await self.run_full_cycle()
            elapsed = time.time() - start_time
            sleep_time = max(300, self.config.UPDATE_INTERVAL - elapsed)  # –ú–∏–Ω–∏–º—É–º 5 –º–∏–Ω—É—Ç
            logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {sleep_time} —Å–µ–∫. –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞")
            await asyncio.sleep(sleep_time)