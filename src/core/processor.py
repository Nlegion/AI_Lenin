import asyncio
import time
import logging
from src.core.database.repositories.news_repository import NewsRepository
from src.modules.news_system.fetcher import NewsFetcher
from src.core.lenin_analyzer import EnhancedLeninAnalyzer
from src.core.publisher import TelegramPublisher
from src.core.settings.config import Settings
from src.core.utils.decorators import handle_errors
from src.core.database.db_core import session_scope
from src.core.llama_server import LeninServer
from src.core.rag_system import get_rag_system

logger = logging.getLogger(__name__)


class OptimizedNewsProcessor:
    def __init__(self):
        self.config = Settings()
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OptimizedNewsProcessor")

        self.fetcher = NewsFetcher()
        self.analyzer = None
        self.server = LeninServer()
        self.analyzer_ready = asyncio.Event()

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        asyncio.create_task(self.initialize_components())

        self.publisher = TelegramPublisher()
        self.stats = {
            "news_fetched": 0,
            "news_processed": 0,
            "analyses_published": 0,
            "errors": 0,
            "avg_processing_time": 0
        }
        self.processing_times = []

    async def initialize_components(self):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–µ
            rag_task = asyncio.create_task(self.initialize_rag())

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
            self.analyzer = EnhancedLeninAnalyzer()
            await self.analyzer.initialize_session()

            # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG
            await rag_task

            self.analyzer_ready.set()
            logger.info("–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

        except Exception as e:
            logger.exception(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}")
            await self.publisher.send_admin_notification(
                f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)[:300]}"
            )

    async def initialize_rag(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã"""
        try:
            rag_system = get_rag_system()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å
            if rag_system.collection.count() == 0:
                logger.info("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏...")
                await rag_system.build_ontology_index()
            logger.info("RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG: {str(e)}")

    @handle_errors
    async def process_pending_news(self):
        if not self.analyzer_ready.is_set():
            logger.info("–û–∂–∏–¥–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞...")
            await self.analyzer_ready.wait()

        try:
            async with session_scope() as session:
                repo = NewsRepository(session)
                unprocessed = await repo.get_unprocessed_news(limit=5)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –ª–∏–º–∏—Ç

                for news in unprocessed:
                    start_time = time.time()
                    try:
                        analysis = await self.analyzer.generate_analysis(
                            news.title,
                            news.content
                        )

                        if self._is_quality_analysis(analysis):
                            await repo.save_analysis(news.id, analysis)
                            self.stats["news_processed"] += 1

                            # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                            processing_time = time.time() - start_time
                            self.processing_times.append(processing_time)
                            self.stats["avg_processing_time"] = sum(
                                self.processing_times[-10:]
                            ) / min(10, len(self.processing_times))

                        else:
                            logger.warning(f"–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å {news.id}")
                            await repo.mark_as_processed_without_analysis(news.id)

                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏ {news.id}: {str(e)}")
                        self.stats["errors"] += 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
            self.stats["errors"] += 1

    def _is_quality_analysis(self, analysis: str) -> bool:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        if not analysis or len(analysis) < 40:
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —à–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        template_phrases = [
            "—Ç–µ–ø–µ—Ä—å", "—Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º", "–∞–Ω–∞–ª–∏–∑–∏—Ä—É—è",
            "–º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥", "–¥–∞–Ω–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è",
            "–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–æ–≤–æ—Å—Ç–∏", "–∫–∞–∫ –æ—Ç–º–µ—á–∞–ª"
        ]

        text_lower = analysis.lower()
        if any(phrase in text_lower for phrase in template_phrases):
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫—Å–∏—Å—Ç—Å–∫–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
        marxist_terms = [
            "–∫–ª–∞—Å—Å", "–∫–∞–ø–∏—Ç–∞–ª", "–ø—Ä–æ–ª–µ—Ç–∞—Ä–∏–∞—Ç", "–±—É—Ä–∂—É–∞–∑–∏—è",
            "—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è", "–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ", "–¥–∏–∞–ª–µ–∫—Ç–∏–∫–∞"
        ]

        if not any(term in text_lower for term in marxist_terms):
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if analysis.count('.') < 1:
            return False

        return True

    @handle_errors
    async def run_optimized_cycle(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        logger.info("–ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á
        fetch_task = asyncio.create_task(self.fetch_new_news())
        process_task = asyncio.create_task(self.process_pending_news())

        await asyncio.gather(fetch_task, process_task)
        await self.publish_pending_analyses()

        logger.info(
            f"–¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω: –ù–æ–≤–æ—Å—Ç–µ–π: {self.stats['news_fetched']}, "
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.stats['news_processed']}, "
            f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {self.stats['avg_processing_time']:.2f}—Å, "
            f"–û—à–∏–±–æ–∫: {self.stats['errors']}"
        )

    async def start_optimized_processing(self):
        """–ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        logger.info("–ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        await self.publisher.send_admin_notification("üöÄ –°–∏—Å—Ç–µ–º–∞ –ò–ò-–õ–µ–Ω–∏–Ω –∑–∞–ø—É—â–µ–Ω–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")

        # –ü–µ—Ä–≤—ã–π —Ü–∏–∫–ª
        await self.run_optimized_cycle()

        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        while True:
            start_time = time.time()
            await self.run_optimized_cycle()
            elapsed = time.time() - start_time

            # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–∞—É–∑–∞ based –Ω–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            target_cycle_time = 180
            sleep_time = max(30, target_cycle_time - elapsed)  # –ù–µ –º–µ–Ω–µ–µ 30 —Å–µ–∫—É–Ω–¥

            logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {sleep_time} —Å–µ–∫. –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞")
            await asyncio.sleep(sleep_time)